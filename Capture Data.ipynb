{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing requarments\n",
    "#import feedparser as fp\n",
    "#import pandas as pd\n",
    "\n",
    "\n",
    "#connect and parsing the rss\n",
    "#article = fp.parse(\"http://export.arxiv.org/rss/cs\")\n",
    "#entry = article.entries[0]\n",
    "#print (entry.keys())\n",
    "#dict_keys(['id', 'title', 'title_detail', 'links', 'link', 'summary', 'summary_detail', 'authors', 'author', 'author_detail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataChapture (url,N):\n",
    "    #connect and parsing the rss\n",
    "    articles = fp.parse(url)\n",
    "    \n",
    "    try:\n",
    "        #check enteries\n",
    "        testLen = len(articles.entries[N])\n",
    "\n",
    "        try:#\n",
    "            data = pd.DataFrame([]) \n",
    "\n",
    "            for i in range(0, N):\n",
    "                entry = articles.entries[i]\n",
    "\n",
    "            #data cleaning        \n",
    "                #removing <p> and </p> from begining and end of string\n",
    "                if entry.summary[0:3] == '<p>':\n",
    "                    entry.summary = entry.summary[3:]\n",
    "                if entry.summary[-4:] == '</p>':\n",
    "                    entry.summary = entry.summary[:-4]\n",
    "\n",
    "                #cleaning if title has '(arXiv:' \n",
    "                arXiv_Find = entry.title.find('(arXiv:')\n",
    "                if arXiv_Find != -1:\n",
    "                    entry.title = entry.title[:arXiv_Find]\n",
    "\n",
    "            #populate dataframe       \n",
    "                data = data.append(pd.DataFrame({'Title': entry.title, 'Link': entry.link, 'Description':entry.summary}, index=[i]))\n",
    "\n",
    "            #Save data    \n",
    "            data.to_csv(r'Top_N_Papers.csv',index=False)\n",
    "            print('File Top_N_Papers.csv is saved')\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "\n",
    "    except:\n",
    "        print ('Could not pars url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Top_N_Papers.csv is saved\n"
     ]
    }
   ],
   "source": [
    "# normal scenario\n",
    "N = 5 \n",
    "url = \"http://export.arxiv.org/rss/cs\"\n",
    "dataChapture (url,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test scenarios\n",
    "\n",
    "# wrong url\n",
    "#N = 100 \n",
    "#url = \"moe\"\n",
    "#dataChapture (url,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of index\n",
    "#N = 1000 \n",
    "#url = \"http://export.arxiv.org/rss/cs\"\n",
    "#dataChapture (url,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link is valid\n",
      "Link is valid\n",
      "Link is valid\n",
      "Link is valid\n",
      "Link is valid\n"
     ]
    }
   ],
   "source": [
    "#Data Validation\n",
    "data_CSV = pd.read_csv(r'Top_N_Papers.csv')\n",
    "for i in range(0, N):\n",
    "    if data_CSV['Link'][i] == articles.entries[i].link:\n",
    "        print('Link is valid')\n",
    "\n",
    "# we can do same method for all columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
